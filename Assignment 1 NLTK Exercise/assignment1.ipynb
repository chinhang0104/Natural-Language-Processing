{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\chinh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of word tokens in the corpus: 141576\n",
      "the size of the vocabular: 6833\n",
      "the tokenized words of the first sentence in the corpus: ['[', 'Sense', 'and', 'Sensibility', 'by', 'Jane', 'Austen', '1811', ']']\n",
      "\n",
      "q2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\chinh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the top 10 most common words in the romance category: [(',', 3899), ('.', 3736), ('the', 2758), ('and', 1776), ('to', 1502), ('a', 1335), ('of', 1186), ('``', 1045), (\"''\", 1044), ('was', 993)]\n",
      "Frequency of ring in the romance and hobbies categories respectively are 2 and 11\n",
      "Frequency of activities in the romance and hobbies categories respectively are 1 and 11\n",
      "Frequency of love in the romance and hobbies categories respectively are 36 and 8\n",
      "Frequency of sports in the romance and hobbies categories respectively are 3 and 12\n",
      "Frequency of church in the romance and hobbies categories respectively are 29 and 3\n",
      "\n",
      "q3: \n",
      "[Synset('dictionary.n.01')]\n",
      "all synonymous words of the word ‘dictionary’:  ['dictionary', 'lexicon']\n",
      "all hyponyms of the word ‘dictionary’:  [Synset('bilingual_dictionary.n.01'), Synset('desk_dictionary.n.01'), Synset('etymological_dictionary.n.01'), Synset('gazetteer.n.02'), Synset('learner's_dictionary.n.01'), Synset('pocket_dictionary.n.01'), Synset('spell-checker.n.01'), Synset('unabridged_dictionary.n.01')]\n",
      "Path similarity between right_whale.n.01 and novel.n.01 are 0.043478260869565216\n",
      "Path similarity between right_whale.n.01 and minke_whale.n.01 are 0.25\n",
      "Path similarity between right_whale.n.01 and tortoise.n.01 are 0.07692307692307693\n"
     ]
    }
   ],
   "source": [
    "# author: 'Wong Chin Hang'\n",
    "# student_id: '20123808'\n",
    "\n",
    "def q1():\n",
    "    print('q1: {:}'.format(''))\n",
    "    from nltk.corpus import gutenberg as gb\n",
    "    file_id = 'austen-sense.txt'\n",
    "    word_list = gb.words(file_id)\n",
    "    # YOUR CODE\n",
    "    # 1. Print the number of word tokens in the corpus.\n",
    "    import nltk\n",
    "    nltk.download('gutenberg')\n",
    "    print('the number of word tokens in the corpus:', len(word_list))\n",
    "    # 2. Print the size of the vocabulary (number of unique word tokens).\n",
    "    myset = set(word_list)\n",
    "    print('the size of the vocabular:', len(myset))\n",
    "    # 3. Print the tokenized words of the first sentence in the corpus.\n",
    "    sentence = gb.sents(file_id)\n",
    "    print('the tokenized words of the first sentence in the corpus:', sentence[0])\n",
    "    \n",
    "def q2():\n",
    "    print('q2: {:}'.format(''))\n",
    "    import nltk\n",
    "    from nltk.corpus import brown\n",
    "    # Your Code\n",
    "    nltk.download(\"brown\")\n",
    "    # 1. Print the top 10 most common words in the romance category.\n",
    "    from nltk.probability import FreqDist\n",
    "    romance_word_list = brown.words(categories='romance')\n",
    "    print('the top 10 most common words in the romance category:',FreqDist(romance_word_list).most_common(10))\n",
    "    # 2. Print the word frequencies\n",
    "    hobbies_word_list = brown.words(categories='hobbies')\n",
    "    List = ['ring','activities','love','sports','church']\n",
    "    for word in List:\n",
    "        print('Frequency of', word ,'in the romance and hobbies categories respectively are', \\\n",
    "              FreqDist(word.lower() for word in romance_word_list)[word], \\\n",
    "              'and',FreqDist(word.lower() for word in hobbies_word_list)[word])\n",
    "\n",
    "def q3():\n",
    "    print('q3: {:}'.format(''))\n",
    "    from nltk.corpus import wordnet as wn\n",
    "    # Your Code\n",
    "    # 1. Print all synonymous words of the word ‘dictionary’.\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    print(wn.synsets('dictionary'))\n",
    "    print('all synonymous words of the word ‘dictionary’: ', wn.synset('dictionary.n.01').lemma_names())\n",
    "    # 2. Print all hyponyms of the word ‘dictionary’.\n",
    "    print('all hyponyms of the word ‘dictionary’: ', wn.synsets('dictionary')[0].hyponyms())\n",
    "    # 3. Calculate similarities.\n",
    "    right_whale=wn.synset('right_whale.n.01')\n",
    "    List = ['novel.n.01', 'minke_whale.n.01', 'tortoise.n.01']\n",
    "    for word in List:\n",
    "        print('Path similarity between right_whale.n.01 and', word, 'are', \\\n",
    "              right_whale.path_similarity(wn.synset(word)))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    q1()\n",
    "\n",
    "    print()\n",
    "    \n",
    "    q2()\n",
    "\n",
    "    print()\n",
    "    \n",
    "    q3()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
